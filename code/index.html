<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹</title>
    <script src="https://cdn.jsdelivr.net/npm/vue@3.3.4/dist/vue.global.prod.js"></script>
    <style>
        :root {
            --primary-color: #4a90e2;
            --success-color: #4CAF50;
            --error-color: #f44336;
            --text-color: #333;
            --bg-color: #f5f7fa;
            --card-bg: #ffffff;
            --border-radius: 12px;
            --shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        body {
            margin: 0;
            padding: 0;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background-color: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
        }

        .container {
            max-width: 900px;
            margin: 2rem auto;
            padding: 0 20px;
        }

        header {
            text-align: center;
            margin-bottom: 2rem;
            padding: 2rem 0;
            background: linear-gradient(135deg, var(--primary-color), #2c5282);
            color: white;
            border-radius: var(--border-radius);
            box-shadow: var(--shadow);
        }

        header h1 {
            margin: 0;
            font-size: 2.5rem;
            font-weight: 600;
        }

        .section {
            background: var(--card-bg);
            border-radius: var(--border-radius);
            padding: 2rem;
            margin-bottom: 1.5rem;
            box-shadow: var(--shadow);
            transition: transform 0.2s;
        }

        .section:hover {
            transform: translateY(-2px);
        }

        .section h2 {
            margin-top: 0;
            color: var(--primary-color);
            font-size: 1.8rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .section h2 i {
            font-size: 1.5rem;
        }

        .recording-controls {
            display: flex;
            gap: 1rem;
            justify-content: center;
            margin: 1.5rem 0;
        }

        .control-btn {
            padding: 0.8rem 1.5rem;
            border: none;
            border-radius: var(--border-radius);
            background-color: var(--primary-color);
            color: white;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 1rem;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .control-btn i {
            font-size: 1.2rem;
        }

        .control-btn:disabled {
            background-color: #ccc;
            cursor: not-allowed;
            opacity: 0.7;
        }

        .control-btn:hover:not(:disabled) {
            background-color: #357abd;
            transform: translateY(-1px);
        }

        .transcript-area {
            background: var(--bg-color);
            border-radius: var(--border-radius);
            padding: 1.5rem;
            min-height: 120px;
            margin: 1rem 0;
            border: 2px solid #e1e8f0;
        }

        .transcript {
            white-space: pre-wrap;
            word-break: break-word;
            font-size: 1.1rem;
            color: var(--text-color);
        }

        .transcript.processing {
            opacity: 0.7;
        }

        .speech-controls {
            display: flex;
            gap: 1rem;
            justify-content: center;
            margin-top: 1.5rem;
        }

        .status {
            margin-top: 1rem;
            padding: 1rem;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 500;
            animation: fadeIn 0.3s ease;
        }

        .status-ok {
            background-color: #e8f5e9;
            color: var(--success-color);
            border: 1px solid #c8e6c9;
        }

        .status-error {
            background-color: #ffebee;
            color: var(--error-color);
            border: 1px solid #ffcdd2;
        }

        ol {
            padding-left: 1.5rem;
            margin: 1rem 0;
        }

        li {
            margin-bottom: 1rem;
            color: #4a5568;
            font-size: 1.1rem;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .recording .control-btn {
            animation: pulse 2s infinite;
            background-color: var(--error-color);
        }

        .icon {
            display: inline-block;
            width: 24px;
            height: 24px;
            margin-right: 8px;
            vertical-align: middle;
        }

        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid #f3f3f3;
            border-top: 3px solid var(--primary-color);
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
    <!-- æ·»åŠ å›¾æ ‡åº“ -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@mdi/font@6.5.95/css/materialdesignicons.min.css">
</head>
<body>
    <div id="app">
        <div class="container">
            <header>
                <h1>ğŸ™ï¸ æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹</h1>
            </header>

            <div class="section" :class="{ 'recording': isRecording }">
                <h2><i class="mdi mdi-microphone"></i> è¯­éŸ³è¯†åˆ«</h2>
                <div class="recording-controls">
                    <button 
                        :disabled="isRecording" 
                        @click="startRecording"
                        class="control-btn"
                    >
                        <i class="mdi mdi-record"></i>
                        å¼€å§‹å½•éŸ³
                    </button>
                    <button 
                        :disabled="!isRecording" 
                        @click="stopRecording"
                        class="control-btn"
                    >
                        <i class="mdi mdi-stop"></i>
                        åœæ­¢å½•éŸ³
                    </button>
                </div>

                <div class="transcript-area">
                    <div v-if="isProcessing" class="loading"></div>
                    <div class="transcript" :class="{ 'processing': isProcessing }">
                        {{ transcriptText }}
                    </div>
                    <div v-if="isRecording" class="text-red-500 mt-2">
                        å‰©ä½™æ—¶é—´: {{ remainingTime }}ç§’
                    </div>
                </div>
            </div>

            <div class="section">
                <h2><i class="mdi mdi-volume-high"></i> è¯­éŸ³åˆæˆ</h2>
                <div id="testAudioSection">
                    <button 
                        @click="testAudioDevice" 
                        class="control-btn"
                    >
                        <i class="mdi mdi-test-tube"></i>
                        æµ‹è¯•éŸ³é¢‘è®¾å¤‡
                    </button>
                    <div :class="['status', audioStatus.className]">
                        <i :class="['mdi', audioStatus.className === 'status-ok' ? 'mdi-check-circle' : 'mdi-alert']"></i>
                        {{ audioStatus.text }}
                    </div>
                </div>
                
                <div v-show="hasTranscript" class="speech-controls">
                    <button 
                        @click="playText" 
                        :disabled="isPlaying"
                        class="control-btn"
                    >
                        <i class="mdi mdi-play"></i>
                        æ’­æ”¾æœ—è¯»
                    </button>
                    <button 
                        @click="pauseText" 
                        :disabled="!isPlaying"
                        class="control-btn"
                    >
                        <i class="mdi" :class="isPaused ? 'mdi-play' : 'mdi-pause'"></i>
                        {{ isPaused ? 'ç»§ç»­' : 'æš‚åœ' }}
                    </button>
                    <button 
                        @click="cancelText"
                        :disabled="!isPlaying"
                        class="control-btn"
                    >
                        <i class="mdi mdi-stop"></i>
                        åœæ­¢
                    </button>
                </div>
            </div>

            <div class="section">
                <h2><i class="mdi mdi-information"></i> ä½¿ç”¨è¯´æ˜</h2>
                <ol>
                    <li>ç‚¹å‡»"æµ‹è¯•éŸ³é¢‘è®¾å¤‡"ç¡®è®¤ç³»ç»ŸéŸ³é¢‘æ˜¯å¦æ­£å¸¸</li>
                    <li>ç‚¹å‡»"å¼€å§‹å½•éŸ³"å¹¶å…è®¸æµè§ˆå™¨ä½¿ç”¨éº¦å…‹é£</li>
                    <li>è¯´è¯å®Œæˆåç‚¹å‡»"åœæ­¢å½•éŸ³"</li>
                    <li>è¯†åˆ«ç»“æœä¼šè‡ªåŠ¨æœ—è¯»ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨æ’­æ”¾æ§åˆ¶æŒ‰é’®æ‰‹åŠ¨æ§åˆ¶</li>
                </ol>
            </div>
        </div>
    </div>

    <script>
        const { createApp, ref, computed, onMounted } = Vue

        const app = createApp({
            setup() {
                let countdownTimer = null;
                const transcriptText = ref('ç­‰å¾…å½•éŸ³...')
                const isProcessing = ref(false)
                const isRecording = ref(false)
                const isPlaying = ref(false)
                const isPaused = ref(false)
                const audioStatus = ref({
                    text: 'ç­‰å¾…æµ‹è¯•éŸ³é¢‘è®¾å¤‡...',
                    className: 'status-ok'
                })
                const remainingTime = ref(30)

                const hasTranscript = computed(() => {
                    return transcriptText.value && transcriptText.value.trim() !== '' && 
                           transcriptText.value !== 'æ­£åœ¨å½•éŸ³...' && 
                           transcriptText.value !== 'æ­£åœ¨å¤„ç†...' &&
                           transcriptText.value !== 'è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•'
                })

                let mediaRecorder = null
                let audioChunks = []

                let voices = []
                let currentUtterance = null
                let synthesisState = 'idle' 

                const SERVER_CONFIG = {
                    protocol: window.location.protocol,
                    host: window.location.hostname || 'localhost',
                    port: '8000',
                    get baseUrl() {
                        return `${this.protocol}//${this.host}:${this.port}`
                    }
                }

                const transcribeAudio = async (formData) => {
                    try {
                        const response = await fetch(`${SERVER_CONFIG.baseUrl}/transcribe`, {
                            method: 'POST',
                            body: formData
                        })
                        
                        if (!response.ok) {
                            const errorData = await response.json()
                            throw new Error(JSON.stringify(errorData))
                        }
                        
                        return await response.json()
                    } catch (error) {
                        console.error('è¯†åˆ«å¤±è´¥:', error)
                        throw error
                    }
                }

                const cleanup = async () => {
                    if (stream) {
                        stream.getTracks().forEach(track => track.stop())
                        stream = null
                    }
                    mediaRecorder = null
                    audioChunks = []
                }

                const startRecording = async () => {
                    try {
                        console.log('è¯·æ±‚éº¦å…‹é£æƒé™...')
                        remainingTime.value = 30
                        const stream = await navigator.mediaDevices.getUserMedia({ 
                            audio: {
                                channelCount: 1,
                                sampleRate: 16000
                            }
                        })

                        // åˆ›å»º AudioContext ç”¨äºé‡é‡‡æ ·
                        const audioContext = new AudioContext({
                            sampleRate: 16000
                        });
                        
                        const source = audioContext.createMediaStreamSource(stream);
                        const destination = audioContext.createMediaStreamDestination();
                        source.connect(destination);

                        // ä½¿ç”¨å¤„ç†åçš„æµåˆ›å»º MediaRecorder
                        const options = {
                            audioBitsPerSecond: 128000,
                            mimeType: 'audio/webm;codecs=opus'
                        };
                        
                        console.log('ä½¿ç”¨éŸ³é¢‘æ ¼å¼:', options.mimeType);
                        mediaRecorder = new MediaRecorder(destination.stream, options);
                        
                        mediaRecorder.ondataavailable = (event) => {
                            if (event.data.size > 0) {
                                audioChunks.push(event.data);
                            }
                        };
                        
                        mediaRecorder.onstop = async () => {
                            if (countdownTimer) {
                                clearInterval(countdownTimer);
                                countdownTimer = null;
                            }
                            remainingTime.value = 30;

                            if (audioChunks.length === 0) {
                                console.error('æ²¡æœ‰å½•åˆ°éŸ³é¢‘æ•°æ®');
                                transcriptText.value = 'æ²¡æœ‰å½•åˆ°éŸ³é¢‘ï¼Œè¯·é‡è¯•';
                                return;
                            }

                            console.log('å½•éŸ³å·²åœæ­¢ï¼Œå¼€å§‹å¤„ç†éŸ³é¢‘æ•°æ®ã€‚');
                            console.log('éŸ³é¢‘æ•°æ®å—æ•°é‡:', audioChunks.length);
                            
                            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                            console.log('éŸ³é¢‘æ–‡ä»¶å¤§å°:', audioBlob.size, 'bytes');
                            
                            if (audioBlob.size < 1000) {
                                console.error('å½•éŸ³æ–‡ä»¶å¤ªå°');
                                transcriptText.value = 'å½•éŸ³æ—¶é—´å¤ªçŸ­ï¼Œè¯·é‡è¯•';
                                return;
                            }
                            
                            const formData = new FormData();
                            formData.append('audio_file', audioBlob, 'recording.webm');
                            
                            try {
                                transcriptText.value = 'æ­£åœ¨è¯†åˆ«...';
                                const data = await transcribeAudio(formData);
                                transcriptText.value = data.text;
                                
                                if (data.text) {
                                    playText();
                                }
                            } catch (error) {
                                console.error('è¯†åˆ«å¤±è´¥:', error);
                                transcriptText.value = 'è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•';
                            } finally {
                                audioChunks.length = 0;
                                stream.getTracks().forEach(track => track.stop());
                                audioContext.close();
                            }
                        };
                        
                        console.log('å¼€å§‹å½•éŸ³...');
                        isRecording.value = true;
                        audioChunks.length = 0;
                        mediaRecorder.start(10);
                        
                        countdownTimer = setInterval(() => {
                            remainingTime.value--;
                            if (remainingTime.value <= 0) {
                                if (mediaRecorder && mediaRecorder.state === 'recording') {
                                    console.log('å½•éŸ³æ—¶é—´åˆ°ï¼Œè‡ªåŠ¨åœæ­¢');
                                    mediaRecorder.stop();
                                    isRecording.value = false;
                                }
                                clearInterval(countdownTimer);
                                countdownTimer = null;
                            }
                        }, 1000);
                        
                        // 30ç§’åè‡ªåŠ¨åœæ­¢å½•éŸ³
                        setTimeout(() => {
                            if (mediaRecorder && mediaRecorder.state === 'recording') {
                                console.log('å½•éŸ³æ—¶é—´åˆ°ï¼Œè‡ªåŠ¨åœæ­¢');
                                mediaRecorder.stop();
                                isRecording.value = false;
                            }
                        }, 30000);
                        
                    } catch (error) {
                        console.error('å½•éŸ³å¤±è´¥:', error);
                        alert('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·ç¡®ä¿å·²æˆäºˆæƒé™');
                    }
                };

                const stopRecording = () => {
                    if (mediaRecorder && mediaRecorder.state === 'recording') {
                        mediaRecorder.stop();
                        isRecording.value = false;
                        if (countdownTimer) {
                            clearInterval(countdownTimer);
                            countdownTimer = null;
                        }
                        remainingTime.value = 30;
                    }
                };

                const initSpeechSynthesis = async () => {
                    if (!window.speechSynthesis) {
                        console.error('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åˆæˆ');
                        return;
                    }

                    // ç­‰å¾…è¯­éŸ³åˆæˆåˆå§‹åŒ–
                    await new Promise(resolve => {
                        let voices = window.speechSynthesis.getVoices();
                        if (voices.length > 0) {
                            resolve();
                        } else {
                            window.speechSynthesis.onvoiceschanged = () => {
                                voices = window.speechSynthesis.getVoices();
                                resolve();
                            };
                        }
                    });

                    console.log('è¯­éŸ³åˆæˆåˆå§‹åŒ–å®Œæˆ');
                };

                const testAudioDevice = async () => {
                    try {
                        // æ£€æŸ¥è¯­éŸ³åˆæˆæ˜¯å¦å¯ç”¨
                        if (!window.speechSynthesis) {
                            throw new Error('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åˆæˆ')
                        }

                        // æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„è¯­éŸ³
                        const availableVoices = window.speechSynthesis.getVoices()
                        console.log('å½“å‰å¯ç”¨è¯­éŸ³:', availableVoices.map(v => v.name))
                        
                        if (!availableVoices || availableVoices.length === 0) {
                            throw new Error('æœªæ‰¾åˆ°å¯ç”¨çš„è¯­éŸ³ï¼Œè¯·ç¨åå†è¯•')
                        }

                        // åˆ›å»ºæµ‹è¯•éŸ³é¢‘
                        const testAudio = new Audio()
                        testAudio.volume = 0.1
                        testAudio.src = 'data:audio/wav;base64,UklGRjIAAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAAABmYWN0BAAAAAAAAABkYXRhAAAAAA=='
                        
                        // æ’­æ”¾æµ‹è¯•éŸ³é¢‘
                        try {
                            await testAudio.play()
                            audioStatus.value = {
                                text: 'éŸ³é¢‘è®¾å¤‡æ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨',
                                className: 'status-ok'
                            }
                        } catch (playError) {
                            // å¦‚æœæ˜¯è‡ªåŠ¨æ’­æ”¾é™åˆ¶å¯¼è‡´çš„é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨è¯­éŸ³åˆæˆæµ‹è¯•
                            console.log('å°è¯•ä½¿ç”¨è¯­éŸ³åˆæˆæµ‹è¯•...')
                            const utterance = new SpeechSynthesisUtterance('æµ‹è¯•')
                            utterance.volume = 0.1
                            window.speechSynthesis.speak(utterance)
                            
                            audioStatus.value = {
                                text: 'æ­£åœ¨ä½¿ç”¨è¯­éŸ³åˆæˆè¿›è¡Œæµ‹è¯•...',
                                className: 'status-ok'
                            }
                        }
                        
                        return true
                    } catch (error) {
                        console.error('éŸ³é¢‘è®¾å¤‡æµ‹è¯•å¤±è´¥:', error)
                        audioStatus.value = {
                            text: error.message || 'éŸ³é¢‘è®¾å¤‡å¯èƒ½æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥æµè§ˆå™¨è®¾ç½®',
                            className: 'status-error'
                        }
                        return false
                    }
                };

                const cancelText = async () => {
                    window.speechSynthesis.cancel()
                    currentUtterance = null
                    synthesisState = 'idle'
                    isPlaying.value = false
                    isPaused.value = false
                    await new Promise(resolve => setTimeout(resolve, 100))
                };

                const playText = async () => {
                    try {
                        const response = await fetch(`${SERVER_CONFIG.baseUrl}/synthesize`, {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json'
                            },
                            body: JSON.stringify({
                                text: transcriptText.value
                            })
                        });
                
                        if (!response.ok) {
                            throw new Error('è¯­éŸ³åˆæˆå¤±è´¥');
                        }
                
                        const audioBlob = await response.blob();
                        const audioUrl = URL.createObjectURL(audioBlob);
                        const audio = new Audio(audioUrl);
                        
                        audio.onended = () => {
                            isPlaying.value = false;
                            URL.revokeObjectURL(audioUrl);
                        };
                
                        isPlaying.value = true;
                        await audio.play();
                
                    } catch (error) {
                        console.error('æ’­æ”¾å¤±è´¥:', error);
                        isPlaying.value = false;
                    }
                };

                const pauseText = () => {
                    if (synthesisState === 'playing') {
                        window.speechSynthesis.pause()
                        synthesisState = 'paused'
                        isPaused.value = true
                    } else if (synthesisState === 'paused') {
                        window.speechSynthesis.resume()
                        synthesisState = 'playing'
                        isPaused.value = false
                    }
                };

                const createWaveFile = (samples, opts = {}) => {
                    const numChannels = opts.numChannels || 1;
                    const sampleRate = opts.sampleRate || 16000;
                    const bytesPerSample = 2;
                    const blockAlign = numChannels * bytesPerSample;
                    const byteRate = sampleRate * blockAlign;
                    const dataSize = samples.length * bytesPerSample;
                    const buffer = new ArrayBuffer(44 + dataSize);
                    const view = new DataView(buffer);

                    // WAV æ–‡ä»¶å¤´
                    writeString(view, 0, 'RIFF');
                    view.setUint32(4, 36 + dataSize, true);
                    writeString(view, 8, 'WAVE');
                    writeString(view, 12, 'fmt ');
                    view.setUint32(16, 16, true);
                    view.setUint16(20, 1, true);
                    view.setUint16(22, numChannels, true);
                    view.setUint32(24, sampleRate, true);
                    view.setUint32(28, byteRate, true);
                    view.setUint16(32, blockAlign, true);
                    view.setUint16(34, bytesPerSample * 8, true);
                    writeString(view, 36, 'data');
                    view.setUint32(40, dataSize, true);

                    // å†™å…¥é‡‡æ ·æ•°æ®
                    const volume = 0.5;
                    let offset = 44;
                    for (let i = 0; i < samples.length; i++) {
                        const sample = Math.max(-1, Math.min(1, samples[i])) * volume;
                        view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                        offset += 2;
                    }

                    return buffer;
                }

                const writeString = (view, offset, string) => {
                    for (let i = 0; i < string.length; i++) {
                        view.setUint8(offset + i, string.charCodeAt(i));
                    }
                }

                onMounted(async () => {
                    await initSpeechSynthesis()
                })

                return {
                    transcriptText,
                    isProcessing,
                    isRecording,
                    isPlaying,
                    isPaused,
                    hasTranscript,
                    audioStatus,
                    remainingTime,
                    startRecording,
                    stopRecording,
                    testAudioDevice,
                    playText,
                    pauseText,
                    cancelText
                }
            }
        })

        app.mount('#app')
    </script>
</body>
</html>

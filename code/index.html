<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>智能语音助手</title>
    <script src="https://cdn.jsdelivr.net/npm/vue@3.3.4/dist/vue.global.prod.js"></script>
    <style>
        :root {
            --primary-color: #4a90e2;
            --success-color: #4CAF50;
            --error-color: #f44336;
            --text-color: #333;
            --bg-color: #f5f7fa;
            --card-bg: #ffffff;
            --border-radius: 12px;
            --shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        body {
            margin: 0;
            padding: 0;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background-color: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
        }

        .container {
            max-width: 900px;
            margin: 2rem auto;
            padding: 0 20px;
        }

        header {
            text-align: center;
            margin-bottom: 2rem;
            padding: 2rem 0;
            background: linear-gradient(135deg, var(--primary-color), #2c5282);
            color: white;
            border-radius: var(--border-radius);
            box-shadow: var(--shadow);
        }

        header h1 {
            margin: 0;
            font-size: 2.5rem;
            font-weight: 600;
        }

        .section {
            background: var(--card-bg);
            border-radius: var(--border-radius);
            padding: 2rem;
            margin-bottom: 1.5rem;
            box-shadow: var(--shadow);
            transition: transform 0.2s;
        }

        .section:hover {
            transform: translateY(-2px);
        }

        .section h2 {
            margin-top: 0;
            color: var(--primary-color);
            font-size: 1.8rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .section h2 i {
            font-size: 1.5rem;
        }

        .recording-controls {
            display: flex;
            gap: 1rem;
            justify-content: center;
            margin: 1.5rem 0;
        }

        .control-btn {
            padding: 0.8rem 1.5rem;
            border: none;
            border-radius: var(--border-radius);
            background-color: var(--primary-color);
            color: white;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 1rem;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .control-btn i {
            font-size: 1.2rem;
        }

        .control-btn:disabled {
            background-color: #ccc;
            cursor: not-allowed;
            opacity: 0.7;
        }

        .control-btn:hover:not(:disabled) {
            background-color: #357abd;
            transform: translateY(-1px);
        }

        .transcript-area {
            background: var(--bg-color);
            border-radius: var(--border-radius);
            padding: 1.5rem;
            min-height: 120px;
            margin: 1rem 0;
            border: 2px solid #e1e8f0;
        }

        .transcript {
            white-space: pre-wrap;
            word-break: break-word;
            font-size: 1.1rem;
            color: var(--text-color);
        }

        .transcript.processing {
            opacity: 0.7;
        }

        .speech-controls {
            display: flex;
            gap: 1rem;
            justify-content: center;
            margin-top: 1.5rem;
        }

        .status {
            margin-top: 1rem;
            padding: 1rem;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 500;
            animation: fadeIn 0.3s ease;
        }

        .status-ok {
            background-color: #e8f5e9;
            color: var(--success-color);
            border: 1px solid #c8e6c9;
        }

        .status-error {
            background-color: #ffebee;
            color: var(--error-color);
            border: 1px solid #ffcdd2;
        }

        ol {
            padding-left: 1.5rem;
            margin: 1rem 0;
        }

        li {
            margin-bottom: 1rem;
            color: #4a5568;
            font-size: 1.1rem;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .recording .control-btn {
            animation: pulse 2s infinite;
            background-color: var(--error-color);
        }

        .icon {
            display: inline-block;
            width: 24px;
            height: 24px;
            margin-right: 8px;
            vertical-align: middle;
        }

        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid #f3f3f3;
            border-top: 3px solid var(--primary-color);
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
    <!-- 添加图标库 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@mdi/font@6.5.95/css/materialdesignicons.min.css">
</head>
<body>
    <div id="app">
        <div class="container">
            <header>
                <h1>🎙️ 智能语音助手</h1>
            </header>

            <div class="section" :class="{ 'recording': isRecording }">
                <h2><i class="mdi mdi-microphone"></i> 语音识别</h2>
                <div class="recording-controls">
                    <button 
                        :disabled="isRecording" 
                        @click="startRecording"
                        class="control-btn"
                    >
                        <i class="mdi mdi-record"></i>
                        开始录音
                    </button>
                    <button 
                        :disabled="!isRecording" 
                        @click="stopRecording"
                        class="control-btn"
                    >
                        <i class="mdi mdi-stop"></i>
                        停止录音
                    </button>
                </div>

                <div class="transcript-area">
                    <div v-if="isProcessing" class="loading"></div>
                    <div class="transcript" :class="{ 'processing': isProcessing }">
                        {{ transcriptText }}
                    </div>
                </div>
            </div>

            <div class="section">
                <h2><i class="mdi mdi-volume-high"></i> 语音合成</h2>
                <div id="testAudioSection">
                    <button 
                        @click="testAudioDevice" 
                        class="control-btn"
                    >
                        <i class="mdi mdi-test-tube"></i>
                        测试音频设备
                    </button>
                    <div :class="['status', audioStatus.className]">
                        <i :class="['mdi', audioStatus.className === 'status-ok' ? 'mdi-check-circle' : 'mdi-alert']"></i>
                        {{ audioStatus.text }}
                    </div>
                </div>
                
                <div v-show="hasTranscript" class="speech-controls">
                    <button 
                        @click="playText" 
                        :disabled="isPlaying"
                        class="control-btn"
                    >
                        <i class="mdi mdi-play"></i>
                        播放朗读
                    </button>
                    <button 
                        @click="pauseText" 
                        :disabled="!isPlaying"
                        class="control-btn"
                    >
                        <i class="mdi" :class="isPaused ? 'mdi-play' : 'mdi-pause'"></i>
                        {{ isPaused ? '继续' : '暂停' }}
                    </button>
                    <button 
                        @click="cancelText"
                        :disabled="!isPlaying"
                        class="control-btn"
                    >
                        <i class="mdi mdi-stop"></i>
                        停止
                    </button>
                </div>
            </div>

            <div class="section">
                <h2><i class="mdi mdi-information"></i> 使用说明</h2>
                <ol>
                    <li>点击"测试音频设备"确认系统音频是否正常</li>
                    <li>点击"开始录音"并允许浏览器使用麦克风</li>
                    <li>说话完成后点击"停止录音"</li>
                    <li>识别结果会自动朗读，也可以使用播放控制按钮手动控制</li>
                </ol>
            </div>
        </div>
    </div>

    <script>
        const { createApp, ref, computed, onMounted } = Vue

        const app = createApp({
            setup() {
                const transcriptText = ref('等待录音...')
                const isProcessing = ref(false)
                const isRecording = ref(false)
                const isPlaying = ref(false)
                const isPaused = ref(false)
                const audioStatus = ref({
                    text: '等待测试音频设备...',
                    className: 'status-ok'
                })

                const hasTranscript = computed(() => {
                    return transcriptText.value && transcriptText.value.trim() !== '' && 
                           transcriptText.value !== '正在录音...' && 
                           transcriptText.value !== '正在处理...' &&
                           transcriptText.value !== '识别失败，请重试'
                })

                let mediaRecorder = null
                let audioChunks = []

                let voices = []
                let currentUtterance = null
                let synthesisState = 'idle' 

                const SERVER_CONFIG = {
                    protocol: window.location.protocol,
                    host: window.location.hostname || 'localhost',
                    port: '8000',
                    get baseUrl() {
                        return `${this.protocol}//${this.host}:${this.port}`
                    }
                }

                const transcribeAudio = async (formData) => {
                    try {
                        const response = await fetch(`${SERVER_CONFIG.baseUrl}/transcribe`, {
                            method: 'POST',
                            body: formData
                        })
                        
                        if (!response.ok) {
                            const errorData = await response.json()
                            throw new Error(JSON.stringify(errorData))
                        }
                        
                        return await response.json()
                    } catch (error) {
                        console.error('识别失败:', error)
                        throw error
                    }
                }

                const cleanup = async () => {
                    if (stream) {
                        stream.getTracks().forEach(track => track.stop())
                        stream = null
                    }
                    mediaRecorder = null
                    audioChunks = []
                }

                const startRecording = async () => {
                    try {
                        console.log('请求麦克风权限...')
                        const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
                        
                        // 检查支持的音频格式
                        const mimeType = 'audio/webm'
                        console.log('使用音频格式:', mimeType)
                        
                        mediaRecorder = new MediaRecorder(stream, { mimeType })
                        
                        mediaRecorder.ondataavailable = (event) => {
                            if (event.data.size > 0) {
                                audioChunks.push(event.data)
                            }
                        }
                        
                        mediaRecorder.onstop = async () => {
                            console.log('录音已停止，开始处理音频数据。')
                            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' })
                            
                            // 创建FormData对象
                            const formData = new FormData()
                            formData.append('audio_file', audioBlob, 'recording.webm')
                            
                            try {
                                const data = await transcribeAudio(formData)
                                transcriptText.value = data.text
                                
                                // 自动播放转录结果
                                if (data.text) {
                                    playText()
                                }
                            } catch (error) {
                                console.error('识别失败:', error)
                                transcriptText.value = '识别失败，请重试'
                            }
                            
                            // 清理录音数据
                            audioChunks = []
                            stream.getTracks().forEach(track => track.stop())
                        }
                        
                        console.log('获得麦克风权限')
                        isRecording.value = true
                        audioChunks = []
                        mediaRecorder.start()
                        console.log('开始录音')
                        
                    } catch (error) {
                        console.error('录音失败:', error)
                        alert('无法访问麦克风，请确保已授予权限')
                    }
                }

                const stopRecording = () => {
                    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                        console.log('停止录音')
                        isRecording.value = false
                        mediaRecorder.stop()
                    }
                }

                const initSpeechSynthesis = async () => {
                    console.log('开始初始化语音合成...')
                    
                    // 等待语音列表加载
                    if (window.speechSynthesis.getVoices().length === 0) {
                        await new Promise((resolve) => {
                            window.speechSynthesis.onvoiceschanged = () => {
                                voices = window.speechSynthesis.getVoices()
                                console.log('语音列表加载完成，可用语音数量:', voices.length)
                                resolve()
                            }
                        })
                    } else {
                        voices = window.speechSynthesis.getVoices()
                        console.log('语音列表已存在，可用语音数量:', voices.length)
                    }

                    // 初始化后设置状态为未测试
                    audioStatus.value = {
                        text: '点击"测试音频设备"按钮进行测试',
                        className: 'status-ok'
                    }
                }

                const testAudioDevice = async () => {
                    try {
                        // 检查语音合成是否可用
                        if (!window.speechSynthesis) {
                            throw new Error('浏览器不支持语音合成')
                        }

                        // 检查是否有可用的语音
                        const availableVoices = window.speechSynthesis.getVoices()
                        console.log('当前可用语音:', availableVoices.map(v => v.name))
                        
                        if (!availableVoices || availableVoices.length === 0) {
                            throw new Error('未找到可用的语音，请稍后再试')
                        }

                        // 创建测试音频
                        const testAudio = new Audio()
                        testAudio.volume = 0.1
                        testAudio.src = 'data:audio/wav;base64,UklGRjIAAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAAABmYWN0BAAAAAAAAABkYXRhAAAAAA=='
                        
                        // 播放测试音频
                        try {
                            await testAudio.play()
                            audioStatus.value = {
                                text: '音频设备正常，可以开始使用',
                                className: 'status-ok'
                            }
                        } catch (playError) {
                            // 如果是自动播放限制导致的错误，尝试使用语音合成测试
                            console.log('尝试使用语音合成测试...')
                            const utterance = new SpeechSynthesisUtterance('测试')
                            utterance.volume = 0.1
                            window.speechSynthesis.speak(utterance)
                            
                            audioStatus.value = {
                                text: '正在使用语音合成进行测试...',
                                className: 'status-ok'
                            }
                        }
                        
                        return true
                    } catch (error) {
                        console.error('音频设备测试失败:', error)
                        audioStatus.value = {
                            text: error.message || '音频设备可能有问题，请检查浏览器设置',
                            className: 'status-error'
                        }
                        return false
                    }
                }

                const cancelText = async () => {
                    window.speechSynthesis.cancel()
                    currentUtterance = null
                    synthesisState = 'idle'
                    isPlaying.value = false
                    isPaused.value = false
                    await new Promise(resolve => setTimeout(resolve, 100))
                }

                const playText = async () => {
                    if (!transcriptText.value) return
                    
                    if (currentUtterance) {
                        window.speechSynthesis.cancel()
                    }
                    
                    const utterance = new SpeechSynthesisUtterance(transcriptText.value)
                    if (voices && voices.length > 0) {
                        // 优先选择中文语音
                        const chineseVoice = voices.find(voice => 
                            voice.lang.includes('zh') || voice.lang.includes('cmn')
                        )
                        utterance.voice = chineseVoice || voices[0]
                    }
                    
                    utterance.rate = 1
                    utterance.pitch = 1
                    utterance.volume = 1

                    utterance.onstart = () => {
                        isPlaying.value = true
                        isPaused.value = false
                    }
                    
                    utterance.onend = () => {
                        isPlaying.value = false
                        isPaused.value = false
                        currentUtterance = null
                    }
                    
                    utterance.onpause = () => {
                        isPaused.value = true
                    }
                    
                    utterance.onresume = () => {
                        isPaused.value = false
                    }
                    
                    currentUtterance = utterance
                    window.speechSynthesis.speak(utterance)
                }

                const pauseText = () => {
                    if (synthesisState === 'playing') {
                        window.speechSynthesis.pause()
                        synthesisState = 'paused'
                        isPaused.value = true
                    } else if (synthesisState === 'paused') {
                        window.speechSynthesis.resume()
                        synthesisState = 'playing'
                        isPaused.value = false
                    }
                }

                onMounted(async () => {
                    await initSpeechSynthesis()
                })

                return {
                    transcriptText,
                    isProcessing,
                    isRecording,
                    isPlaying,
                    isPaused,
                    hasTranscript,
                    audioStatus,
                    startRecording,
                    stopRecording,
                    testAudioDevice,
                    playText,
                    pauseText,
                    cancelText
                }
            }
        })

        app.mount('#app')
    </script>
</body>
</html>
